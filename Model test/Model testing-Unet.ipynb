{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing of trained U-net:\n",
    "\n",
    "# Load images for model testing\n",
    "# Construct model structure\n",
    "# Load trained model weights\n",
    "# Peform image segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of conv_block\n",
    "\n",
    "def conv_block(inputs, filter_size, size, dropout, batch_norm):\n",
    "    \n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(inputs)\n",
    "\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
    "\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "    \n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout)(conv)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of Unet architecture\n",
    "\n",
    "def Unet(input_shape, NUM_CLASSES, dropout_rate, batch_norm):\n",
    "\n",
    "    # network structure\n",
    "    FILTER_NUM = 32 # number of filters for the first layer\n",
    "    FILTER_SIZE = 3 # size of the convolutional filter\n",
    "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
    "\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Downsampling layers\n",
    "\n",
    "    # DownRes 1, convolution + pooling\n",
    "    conv_1 = conv_block(inputs, FILTER_SIZE, 1*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_1)\n",
    "\n",
    "    # DownRes 2, convolution + pooling\n",
    "    conv_2 = conv_block(pool_1, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_2)\n",
    "\n",
    "    # DownRes 3, convolution + pooling\n",
    "    conv_3 = conv_block(pool_2, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_3)\n",
    "\n",
    "    # DownRes 4\n",
    "    conv_4 = conv_block(pool_3, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(conv_4)\n",
    "\n",
    "    # DownRes 5, convolution only\n",
    "    conv_5 = conv_block(pool_4, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "\n",
    "    # UpRes 1, upsampling  + concatenate\n",
    "    up_1 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_5)\n",
    "    up_1 = layers.concatenate([up_1, conv_4], axis=3)\n",
    "    up_conv_1 = conv_block(up_1, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "   \n",
    "    # UpRes 2, upsampling  + concatenate\n",
    "    up_2 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_1)\n",
    "    up_2 = layers.concatenate([up_2, conv_3], axis=3)\n",
    "    up_conv_2 = conv_block(up_2, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    \n",
    "    # UpRes 3, upsampling  + concatenate\n",
    "    up_3 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_2)\n",
    "    up_3 = layers.concatenate([up_3, conv_2], axis=3)\n",
    "    up_conv_3 = conv_block(up_3, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # UpRes 4, upsampling  + concatenate\n",
    "    up_4 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_3)\n",
    "    up_4 = layers.concatenate([up_4, conv_1], axis=3)\n",
    "    up_conv_4 = conv_block(up_4, FILTER_SIZE, 1*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # 1*1 convolutional layers\n",
    "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_4)\n",
    "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
    "    conv_final = layers.Activation('softmax')(conv_final)  #Change to softmax for multichannel\n",
    "\n",
    "    # Model \n",
    "    model = models.Model(inputs, conv_final, name=\"Unet\")\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size of images and input shape\n",
    "SIZE_X = 256 \n",
    "SIZE_Y = 512\n",
    "input_shape = (SIZE_X,SIZE_Y,1)\n",
    "\n",
    "#Number of classes for segmentation\n",
    "n_classes=5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load X-ray images for model testing\n",
    "\n",
    "test_images = []\n",
    "\n",
    "for directory_path in glob.glob(\"images/\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        img = cv2.imread(img_path, 0)       \n",
    "        #img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        test_images.append(img)\n",
    "       \n",
    "#Convert list to array for machine learning processing        \n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the U-net model\n",
    "model = Unet(input_shape, NUM_CLASSES=5, dropout_rate=0.0, batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-trained model weights\n",
    "\n",
    "model.load_weights('Unet-1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_images)\n",
    "y_pred_argmax=np.argmax(y_pred, axis=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1c0582f30543fff29a5261a1abd13119b0f120c9034b64de73a59460f47c2f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
